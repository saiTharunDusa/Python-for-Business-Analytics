# -*- coding: utf-8 -*-
"""Welcome To Colab

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/notebooks/intro.ipynb
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

pd.set_option('display.max_columns', None)
pd.set_option('display.expand_frame_repr', False)
# reading the file.
census_income_df = pd.read_csv('/content/census_income.csv')

# print the header
print(census_income_df.head())
print()

# show the descriptive statistics.
print("Descriptive Statistics: ")
print(census_income_df.describe())
print()

"""1. From the descriptive statistics, we could analyze that number of hours people worked for a week is 40 on an average.
2. The data consists of people between the age group from 17 to 90.
3. The average of income_above_50k is 0.2 which means that there are very a few people with inomce above 50k.
4. The education level is across the 1 to 16 levels. That means the given data consists of people from different educational background.
"""

# Histogram for income distribution.
plt.hist(census_income_df['income'], bins = 10, rwidth = 0.9)

# Set labels and title
plt.xlabel('Income')
plt.ylabel('Frequency')
plt.title('Income above 50K distribution')
plt.show()

"""1. From the above Histogram, It is clearly known that about 8000 people are with income above 50K and about 24000 people are with below 50k income."""

# Bar Plot
# Group the data by 'age' and calculate the mean of 'income_above_50k' for each age
Age_income_mean = census_income_df.groupby('age')['income_above_50k'].mean()

plt.figure(figsize=(12, 6))
# Create a bar plot using plt.bar()
plt.bar(Age_income_mean.index, Age_income_mean.values)

# Set labels and title
plt.xlabel('Age')
plt.ylabel('Mean proportions of Individuals Earning Above $50,000')
plt.title('Income Distribution by Age')

# # Rotate x-axis labels for better readability
plt.xticks(rotation=45)

# Display the plot
plt.show()

"""1. As individuals age, their earnings typically rise until they reach their 40s or 50s. According to the graph, the percentage of individuals earning over $50,000 steadily increases until around the age of 40. After that point, it stabilizes and may even experience a slight decline.

2. Young adults have a relatively low proportion of individuals earning over $50,000.

3. The graph illustrates that less than 20% of individuals aged between 20 and 30 earn more than $50,000. This can be attributed to various factors, such as lower wages for entry-level positions and the fact that many young adults are still pursuing their education.
"""

# Bar Plot
# Group the data by 'education_level' and calculate the mean of 'income_above_50k' for each age
education_level_income_mean = census_income_df.groupby('education_level')['income_above_50k'].mean()

plt.figure(figsize=(12, 6))
# Create a bar plot using plt.bar()
plt.bar(education_level_income_mean.index, education_level_income_mean.values)

# Set labels and title
plt.xlabel('Education Level')
plt.ylabel('Mean proportions of Individuals Earning Above $50,000')
plt.title('Income Distribution by education level')

# # Rotate x-axis labels for better readability
plt.xticks(rotation=45)

# Display the plot
plt.show()

"""1. The graph clearly illustrates that as education level increases, the likelihood of earning more than $50,000 per year also increases. The y-axis represents the proportion of people, while the x-axis represents education level. Starting from a low point, the line steadily rises, indicating that education plays a significant role in determining income levels.

2. According to the graph, individuals with a professional degree have the highest probability of earning more than $50,000. The line on the graph reaches its peak at the education level associated with a professional degree, highlighting the strong correlation between professional degrees and higher incomes.
"""

# Bar Plot
from sklearn.preprocessing import LabelEncoder
# converting categorical data to numeric.
census_income_df['marital_status_numeric'] = LabelEncoder().fit_transform(census_income_df['marital_status'])
# Married-civ-spouse - 0
# Divorced - 1
# Never-married - 2
# Separated - 3
# Widowed - 4
# Married-spouse-absent - 5
# Married-AF-spouse - 6

# Group the data by 'marital_status_numeric' and calculate the mean of 'income_above_50k' for each marital status
marital_status_income_mean = census_income_df.groupby('marital_status_numeric')['income_above_50k'].mean()

# Plotting the bar chart
plt.figure(figsize=(12, 6))
plt.bar(marital_status_income_mean.index, marital_status_income_mean.values)

# Set labels and title
plt.xlabel('Marital Status (Numeric)')
plt.ylabel('Mean Proportion of Individuals Earning Above $50,000')
plt.title('Income Distribution by Marital Status (Numeric)')

# Rotate x-axis labels for better readability
plt.xticks(rotation=45)

# Display the plot
plt.show()

"""1. No one who is married to a civilian spouse (Married-civ-spouse) earns more than $50,000.

2. All divorced individuals (Divorced) earn more than $50,000.

3. A significant number of people who have never been married (Never-married) earn more than $50,000.

4. The income distribution for the other marital statuses (Separated, Widowed, Married-spouse-absent, Married-AF-spouse) is inconclusive due to data limitations on the y-axis.
"""

x = census_income_df[['age', 'hours_per_week']]
y = census_income_df['income_above_50k']

k = 15
new_age = 52
new_hour = 45
target_values = [[new_age,new_hour]]

#knn
from sklearn.neighbors import KNeighborsClassifier
knn_classifier = KNeighborsClassifier(n_neighbors=k)
knn_classifier.fit(x,y)
#print the prediction
print("KNN Classifier of whether the income is greater than 50k or not ")
print(knn_classifier.predict(target_values))
print()

# Decision tree
from sklearn.tree import DecisionTreeClassifier
dt_classifier = DecisionTreeClassifier(max_depth = 3)
dt_classifier.fit(x,y)
#print the prediction
print("Decision Tree Classifier of whether the income is greater than 50k or not ")
print(dt_classifier.predict(target_values))
print()

# Random Forest
from sklearn.ensemble import RandomForestClassifier
rf_classifier = RandomForestClassifier()
rf_classifier.fit(x, y)
#print the prediction
print("Random Forest Classifier of whether the income is greater than 50k or not ")
print(dt_classifier.predict(target_values))
print()

# Neural Networks
from sklearn.neural_network import MLPClassifier
nn_classifier = MLPClassifier()
nn_classifier.fit(x, y)
#print the prediction
print("Neural Networks Classifier of whether the income is greater than 50k or not ")
print(dt_classifier.predict(target_values))
print()

# let us test the models.
#train test split
from sklearn.model_selection import train_test_split
trainingx, testx, trainingy, testy = train_test_split(x,y, random_state = 1)

#K Nearest Neighbour
knn_classifier = KNeighborsClassifier(n_neighbors = k)
knn_classifier.fit(trainingx,trainingy)
predicted = knn_classifier.predict(testx)
prediction_error = abs(predicted - testy)
print("K Nearest Neighbour prediction score : ")
print(np.mean(prediction_error))
print()

#Decision Tree
dt_classifier = DecisionTreeClassifier(max_depth = 3)
dt_classifier.fit(trainingx,trainingy)
predicted = dt_classifier.predict(testx)
prediction_error = abs(predicted - testy)
print("Decision Tree prediction score : ")
print(np.mean(prediction_error))
print()

#Random forest
rf_classifier = RandomForestClassifier()
rf_classifier.fit(trainingx,trainingy)
predicted = rf_classifier.predict(testx)
prediction_error = abs(predicted - testy)
print("Raondom Forest  prediction score : ")
print(np.mean(prediction_error))
print()

#neural network
nn_classifier = MLPClassifier()
nn_classifier.fit(trainingx,trainingy)
predicted = nn_classifier.predict(testx)
prediction_error = abs(predicted - testy)
print("Neural Network  prediction score : ")
print(np.mean(prediction_error))
print()

"""1. Classifier Predictions
KNN Classifier: Predicted [1] (income > $50k)
Decision Tree Classifier: Predicted [1] (income > $50k)
Random Forest Classifier: Predicted [1] (income > $50k)
Neural Network Classifier: Predicted [1] (income > $50k)
All the classifiers have agreed on predicting an income greater than $50k, showing a unanimous decision on the classification outcome for the specific instance(s).

2. Prediction Scores (Accuracy)
K Nearest Neighbors (KNN): Prediction score (accuracy) = 0.2295786758383491
Decision Tree: Prediction score (accuracy) = 0.23547475740081072
Random Forest: Prediction score (accuracy) = 0.23215821152192606
Neural Network: Prediction score (accuracy) = 0.22626212995946443
The prediction scores, ranging from around 22.6% to 23.5%, indicate the accuracy of each classifier in determining whether the income exceeds $50k or not in a test dataset. These scores reflect the proportion of correct predictions made by each model.

3. Interpretation
The unanimous forecast ([1]) from all classifiers indicates their agreement in categorizing income based on the provided input features.
The prediction scores offer valuable information about the overall effectiveness of each classifier, with accuracy rates varying between approximately 22.6% and 23.5%. Although these accuracies may seem relatively low, they demonstrate the models' capability to accurately classify income categories using the test dataset.
"""